{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reinforce_pytorch.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVkCC1iri2SN"
      },
      "source": [
        "# REINFORCE in PyTorch\n",
        "\n",
        "Just like we did before for Q-learning, this time we'll design a PyTorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
        "\n",
        "Most of the code in this notebook is taken from approximate Q-learning, so you'll find it more or less familiar and even simpler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjkAlO8Qi_Xm"
      },
      "source": [
        "Acknowledgements for this great notebook to the [Practical_RL](https://github.com/yandexdataschool/Practical_RL) course team."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpr1cah_mSLk",
        "outputId": "8e5000a4-803c-473d-8fd7-c19df0e59280"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (6.3.0)\n",
            "Collecting farama-notifications>=0.0.1\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (2.2.1)\n",
            "Collecting jax-jumpy>=1.0.0\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gymnasium) (3.15.0)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b0moDpxi2SW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1494f6b9-056e-4193-90c8-dae720aa8224"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sj8sGFcvm60p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UYczVTli2Sb"
      },
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98zhewLFi2Sd"
      },
      "source": [
        "A caveat: with some versions of `pyglet`, the following cell may crash with `NameError: name 'base' is not defined`. The corresponding bug report is [here](https://github.com/pyglet/pyglet/issues/134). If you see this error, try restarting the kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPKYrIlai2Sf"
      },
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0GEMsrhnLTj",
        "outputId": "99c81c45-cdc5-4056-832e-9ba25061b42b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.0231731 , -0.0132879 ,  0.03220604, -0.01076773], dtype=float32),\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75eHkuwTi2Si"
      },
      "source": [
        "# Building the network for REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_TFCmsWi2Sj"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY2THBWfi2Sl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_pYr7PZi2Sn"
      },
      "source": [
        "# Build a simple neural network that predicts policy logits. \n",
        "# Keep it simple: CartPole isn't worth deep architectures.\n",
        "model = nn.Sequential(*[\n",
        "    nn.Linear(state_dim[0], 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, n_actions)\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s, _ = env.reset()"
      ],
      "metadata": {
        "id": "yS1sAC_loRLa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([s]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho9r8hpqoPTl",
        "outputId": "5c4c8d36-a682-43b3-eb31-dc10b6783a09"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-ce57aa602f39>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  model(torch.tensor([s]))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1469, 0.0925]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y80qbQFi2Sq"
      },
      "source": [
        "#### Predict function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PjRu0mi2Sr"
      },
      "source": [
        "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
        "So, here gradient calculation is not needed.\n",
        "<br>\n",
        "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
        "to suppress gradient calculation.\n",
        "<br>\n",
        "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
        "<br>\n",
        "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
        "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
        "<br>\n",
        "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5B5JuXCi2St"
      },
      "source": [
        "def predict_probs(states):\n",
        "    \"\"\" \n",
        "    Predict action probabilities given states.\n",
        "    :param states: numpy array of shape [batch, state_shape]\n",
        "    :returns: numpy array of shape [batch, n_actions]\n",
        "    \"\"\"\n",
        "    # convert states, compute logits, use softmax to get probability\n",
        "    logits = model(torch.from_numpy(states)).detach().cpu()\n",
        "    probs = torch.softmax(logits, dim=1).numpy()\n",
        "    return probs"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obkl_jCii2Sv"
      },
      "source": [
        "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
        "test_probas = predict_probs(test_states)\n",
        "assert isinstance(test_probas, np.ndarray), \\\n",
        "    \"you must return np array and not %s\" % type(test_probas)\n",
        "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
        "    \"wrong output shape: %s\" % np.shape(test_probas)\n",
        "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be6AYf8gi2Sw"
      },
      "source": [
        "### Play the game\n",
        "\n",
        "We can now use our newly built agent to play the game."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LOUUvnki2Sx"
      },
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\" \n",
        "    Play a full session with REINFORCE agent.\n",
        "    Returns sequences of states, actions, and rewards.\n",
        "    \"\"\"\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "    s, _ = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probs = predict_probs(np.array([s]))[0]\n",
        "\n",
        "        # Sample action with given probabilities.\n",
        "        a = np.random.choice(n_actions, p=action_probs)\n",
        "        new_s, r, done, info, _ = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return states, actions, rewards"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sdENWJAi2Sz"
      },
      "source": [
        "# test it\n",
        "states, actions, rewards = generate_session(env)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG5hLg-3i2S0"
      },
      "source": [
        "### Computing cumulative rewards\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
        "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
        "&= r_t + \\gamma * G_{t + 1}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoWX9gvai2S0"
      },
      "source": [
        "def get_cumulative_rewards(rewards,  # rewards at each step\n",
        "                           gamma=0.99  # discount for reward\n",
        "                           ):\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session \n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "    \n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    cumulative_rewards_reversed = [0 for _ in rewards]\n",
        "    prev_cumulative_reward = 0\n",
        "    for idx, reward in enumerate(rewards[::-1]):\n",
        "      cumulative_rewards_reversed[idx] = reward + gamma * prev_cumulative_reward\n",
        "      prev_cumulative_reward = cumulative_rewards_reversed[idx]\n",
        "\n",
        "    return np.asarray(cumulative_rewards_reversed[::-1])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DX39wcUi2S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af9c70a-99ed-4529-d8a6-1213559c90ce"
      },
      "source": [
        "get_cumulative_rewards(rewards)\n",
        "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "    [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evLt5DJji2S_"
      },
      "source": [
        "#### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
        "\n",
        "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
        "\n",
        "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
        "\n",
        "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hLjxTVLi2TB"
      },
      "source": [
        "def to_one_hot(y_tensor, ndims):\n",
        "    \"\"\" helper: take an integer vector and convert it to 1-hot matrix. \"\"\"\n",
        "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
        "    y_one_hot = torch.zeros(\n",
        "        y_tensor.size()[0], ndims).scatter_(1, y_tensor, 1)\n",
        "    return y_one_hot"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C8ZSizji2TD"
      },
      "source": [
        "# Your code: define optimizers\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "\n",
        "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # cast everything into torch tensors\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    actions = torch.tensor(actions, dtype=torch.int32)\n",
        "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
        "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
        "\n",
        "    # predict logits, probas and log-probas using an agent.\n",
        "    logits = model(states)\n",
        "    probs = nn.functional.softmax(logits, -1)\n",
        "    log_probs = nn.functional.log_softmax(logits, -1)\n",
        "\n",
        "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
        "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    log_probs_for_actions = torch.sum(\n",
        "        log_probs * to_one_hot(actions, env.action_space.n), dim=1)\n",
        "   \n",
        "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef` \n",
        "    entropy = -torch.sum(log_probs * probs, dim=1).mean()\n",
        "    # <YOUR CODE>\n",
        "    loss = -torch.mean(log_probs_for_actions * cumulative_returns) # <YOUR CODE>\n",
        "\n",
        "    optimized_function = loss - entropy_coef * entropy\n",
        "    # Gradient descent step\n",
        "    optimizer.zero_grad()\n",
        "    optimized_function.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return np.sum(rewards)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-WWsbl5i2TE"
      },
      "source": [
        "### The actual training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckHj5sXBi2TE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792105fd-98aa-4428-d87c-2ce623575c94"
      },
      "source": [
        "for i in range(100):\n",
        "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
        "    \n",
        "    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n",
        "    \n",
        "    if np.mean(rewards) > 475:\n",
        "        print(\"You Win!\")  # but you can train even further\n",
        "        break"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean reward:231.220\n",
            "mean reward:186.140\n",
            "mean reward:372.760\n",
            "mean reward:646.720\n",
            "You Win!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.utils.save_video import save_video"
      ],
      "metadata": {
        "id": "LJ0Y6LcywmM3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")"
      ],
      "metadata": {
        "id": "jsUtoe8lwm41"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "id": "QB3kBzIIyC-2",
        "outputId": "e221a18a-e922-40f4-c143-00b3ea2ff96b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.03452038, -0.03385395, -0.02906066, -0.01981678], dtype=float32),\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gym.__version__"
      ],
      "metadata": {
        "id": "H8p8WUUByMwk",
        "outputId": "e325eb9e-2cfa-43ea-be90-fec34e01c014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.28.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(env.render()[0])"
      ],
      "metadata": {
        "id": "-dbdtUFHycZW",
        "outputId": "0b85caaa-178e-433a-e5c6-cbf810daba97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f852cfc9460>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(env.render())"
      ],
      "metadata": {
        "id": "xgoDQEm5yiPY",
        "outputId": "27bdb347-fde6-4181-a2ad-d6fe4a3c72a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f852cb7e2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.utils.save_video import save_video\n",
        "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
        "\n",
        "step_starting_index = 0\n",
        "episode_index = 0\n",
        "frames = []\n",
        "s, _ = env.reset()\n",
        "for step_index in range(1000):\n",
        "\n",
        "    action_probs = predict_probs(np.array([s]))[0]\n",
        "    a = np.random.choice(n_actions, p=action_probs)\n",
        "\n",
        "    frames.append(env.render())\n",
        "\n",
        "    s, r, done, info, _ = env.step(a)\n",
        "\n",
        "    if done:\n",
        "        save_video(\n",
        "             frames, \n",
        "             \".\", \n",
        "             fps=env.metadata[\"render_fps\"], \n",
        "             step_starting_index=step_starting_index, \n",
        "             episode_index=episode_index\n",
        "        )\n",
        "        step_starting_index = 0\n",
        "        episode_index += 1\n",
        "        s = env.reset()[0]\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "eUGE8OEOwpKZ",
        "outputId": "b9b5cca4-fbc4-409e-c158-3c089e28e634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/rl-video-episode-0.mp4.\n",
            "Moviepy - Writing video /content/rl-video-episode-0.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/rl-video-episode-0.mp4\n",
            "Moviepy - Building video /content/rl-video-episode-1.mp4.\n",
            "Moviepy - Writing video /content/rl-video-episode-1.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/rl-video-episode-1.mp4\n"
          ]
        }
      ]
    }
  ]
}