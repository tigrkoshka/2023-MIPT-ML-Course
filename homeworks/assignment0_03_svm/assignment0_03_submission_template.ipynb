{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
=======
   "id": "f586d0a5",
   "metadata": {},
>>>>>>> 0af341e (22f basic (#89))
   "source": [
    "Before you submit this notebook, make sure everything runs as expected in the local test cases. \n",
    "Please, paste the solution to the designed cell and do not change anything else.\n",
    "\n",
    "Also, please, leave your first and last names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FirstName = \"Tigran\"\n",
    "LastName = \"Koshkelian\""
=======
   "id": "d4ce3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstName = \"Danial\"\n",
    "LastName = \"Aliev\""
>>>>>>> 0af341e (22f basic (#89))
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
=======
   "id": "5dda42bd",
   "metadata": {},
>>>>>>> 0af341e (22f basic (#89))
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
=======
   "execution_count": 2,
   "id": "a794d533",
   "metadata": {},
>>>>>>> 0af341e (22f basic (#89))
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial.distance import cdist # You can use this for rbf kernel\n",
    "\n",
    "import unittest\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ed73995",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dfd5431f2494f8f56c119aaae6805ca",
     "grade": false,
     "grade_id": "cell-7bfbe050819ecfac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rbf(x_1, x_2, sigma=1.):\n",
<<<<<<< HEAD
    "    \"\"\"Computes rbf kernel for batches of objects\n",
    "\n",
    "    Args:\n",
    "        x_1: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "        x_2: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "    Returns:\n",
    "        kernel function values for all pairs of samples from x_1 and x_2\n",
    "        torch.tensor of type torch.float32 shaped `(#samples_1, #samples_2)`\n",
    "    \"\"\"\n",
    "    x_1_2 = (x_1 ** 2).sum(axis=1).reshape(x_1.shape[0], 1)\n",
    "    x_2_2 = (x_2 ** 2).sum(axis=1).reshape(1, x_2.shape[0])\n",
    "    x_1_x_2 = x_1 @ x_2.T\n",
    "    distances = torch.exp(-(x_1_2 + x_2_2 - 2 * x_1_x_2) / (2 * sigma ** 2))\n",
    "    return torch.Tensor(distances).type(torch.float32)\n",
    "\n",
    "\n",
    "def hinge_loss(scores, labels):\n",
    "    \"\"\"Mean loss for batch of objects\n",
    "    \"\"\"\n",
    "    assert len(scores.shape) == 1\n",
    "    assert len(labels.shape) == 1\n",
    "    return torch.mean(torch.max(torch.zeros(scores.shape[0]), 1 - scores * labels))\n",
    "\n",
    "\n",
    "class SVM(BaseEstimator, ClassifierMixin):\n",
    "    @staticmethod\n",
    "    def linear(x_1, x_2):\n",
    "        \"\"\"Computes linear kernel for batches of objects\n",
=======
    "    dists = (x_1**2).sum(axis=1)[:, np.newaxis]+ (x_2**2).sum(axis=1) - 2 * x_1 @ x_2.T\n",
    "    distances = np.exp(-sigma * dists)\n",
    "    return torch.Tensor(distances).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fb5a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(scores, labels):\n",
    "    '''Mean loss for batch of objects\n",
    "    '''\n",
    "    assert len(scores.shape) == 1\n",
    "    assert len(labels.shape) == 1\n",
    "    return torch.mean(torch.clamp(1 - scores * labels, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a14bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(BaseEstimator, ClassifierMixin):\n",
    "    @staticmethod\n",
    "    def linear(x_1, x_2):\n",
    "        '''Computes linear kernel for batches of objects\n",
>>>>>>> 0af341e (22f basic (#89))
    "        \n",
    "        Args:\n",
    "            x_1: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "            x_2: torch.tensor shaped `(#samples_1, #features)` of type torch.float32\n",
    "        Returns:\n",
    "            kernel function values for all pairs of samples from x_1 and x_2\n",
    "            torch.tensor shaped `(#samples_1, #samples_2)` of type torch.float32\n",
<<<<<<< HEAD
    "        \"\"\"\n",
    "        return x_1 @ x_2.T\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            lr: float = 1e-3,\n",
    "            epochs: int = 2,\n",
    "            batch_size: int = 64,\n",
    "            lmbd: float = 1e-4,\n",
    "            kernel_function=None,\n",
    "            verbose: bool = False,\n",
    "    ):\n",
    "        self.X = None\n",
    "        self.bias = None\n",
    "        self.betas = None\n",
=======
    "        '''\n",
    "        return x_1 @ x_2.T\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float=1e-3,\n",
    "        epochs: int=2,\n",
    "        batch_size: int=64,\n",
    "        lmbd: float=1e-4,\n",
    "        kernel_function=None,\n",
    "        verbose: bool=False,\n",
    "    ):\n",
>>>>>>> 0af341e (22f basic (#89))
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lmbd = lmbd\n",
    "        self.kernel_function = kernel_function or SVM.linear\n",
    "        self.verbose = verbose\n",
    "        self.fitted = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'SVM model, fitted: {self.fitted}'\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        assert (np.abs(Y) == 1).all()\n",
    "        n_obj = len(X)\n",
    "        X, Y = torch.FloatTensor(X), torch.FloatTensor(Y)\n",
    "        K = self.kernel_function(X, X).float()\n",
    "\n",
    "        self.betas = torch.full((n_obj, 1), fill_value=0.001, dtype=X.dtype, requires_grad=True)\n",
<<<<<<< HEAD
    "        self.bias = torch.zeros(1, requires_grad=True)  # I've also add bias to the model\n",
    "\n",
    "        optimizer = optim.SGD((self.betas, self.bias), lr=self.lr)\n",
    "        for epoch in range(self.epochs):\n",
    "            perm = torch.randperm(n_obj)  # Generate a set of random numbers of length: sample size\n",
    "            sum_loss = 0.  # Loss for each epoch\n",
    "            for i in range(0, n_obj, self.batch_size):\n",
    "                batch_inds = perm[i:i + self.batch_size]\n",
    "                y_batch = Y[batch_inds]  # Pick the correlating class\n",
    "                k_batch = K[batch_inds]\n",
    "\n",
    "                optimizer.zero_grad()  # Manually zero the gradient buffers of the optimizer\n",
    "\n",
    "                # get the matrix product using SVM parameters: self.betas and self.bias\n",
    "                preds = k_batch @ self.betas + self.bias\n",
    "                preds = preds.flatten()\n",
    "                loss = self.lmbd * self.betas[batch_inds].T @ k_batch @ self.betas + hinge_loss(preds, y_batch)\n",
    "                loss.backward()  # Backpropagation\n",
    "                optimizer.step()  # Optimize and adjust weights\n",
    "\n",
    "                sum_loss += loss.item()  # Add the loss\n",
    "\n",
    "            if self.verbose: \n",
    "                print(\"Epoch \" + str(epoch) + \", Loss: \" + str(sum_loss / self.batch_size))\n",
=======
    "        self.bias = torch.zeros(1, requires_grad=True) # I've also add bias to the model\n",
    "        \n",
    "        optimizer = optim.SGD((self.betas, self.bias), lr=self.lr)\n",
    "        for epoch in range(self.epochs):\n",
    "            perm = torch.randperm(n_obj)  # Generate a set of random numbers of length: sample size\n",
    "            sum_loss = 0.                 # Loss for each epoch\n",
    "            for i in range(0, n_obj, self.batch_size):\n",
    "                batch_inds = perm[i:i + self.batch_size]\n",
    "                x_batch = X[batch_inds]   # Pick random samples by iterating over random permutation\n",
    "                y_batch = Y[batch_inds]   # Pick the correlating class\n",
    "                k_batch = K[batch_inds]\n",
    "                \n",
    "                optimizer.zero_grad()     # Manually zero the gradient buffers of the optimizer\n",
    "                \n",
    "                preds = k_batch @ self.betas + self.bias### YOUR CODE HERE # get the matrix product using SVM parameters: self.betas and self.bias\n",
    "                preds = preds.flatten()\n",
    "                loss = self.lmbd * self.betas[batch_inds].T @ k_batch @ self.betas + hinge_loss(preds, y_batch)\n",
    "                loss.backward()           # Backpropagation\n",
    "                optimizer.step()          # Optimize and adjust weights\n",
    "\n",
    "                sum_loss += loss.item()   # Add the loss\n",
    "\n",
    "            if self.verbose: print(\"Epoch \" + str(epoch) + \", Loss: \" + str(sum_loss / self.batch_size))\n",
>>>>>>> 0af341e (22f basic (#89))
    "\n",
    "        self.X = X\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict_scores(self, batch):\n",
    "        with torch.no_grad():\n",
    "            batch = torch.from_numpy(batch).float()\n",
    "            K = self.kernel_function(batch, self.X)\n",
    "            # compute the margin values for every object in the batch\n",
<<<<<<< HEAD
    "            return (K @ self.betas + self.bias).flatten()\n",
=======
    "            return (K @ self.betas + self.bias).flatten()### YOUR CODE HERE\n",
>>>>>>> 0af341e (22f basic (#89))
    "\n",
    "    def predict(self, batch):\n",
    "        scores = self.predict_scores(batch)\n",
    "        answers = np.full(len(batch), -1, dtype=np.int64)\n",
    "        answers[scores > 0] = 1\n",
    "        return answers"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
=======
   "id": "e05c5d28",
   "metadata": {},
>>>>>>> 0af341e (22f basic (#89))
   "source": [
    "### Test 0: Initialization (0.01 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d94aa55",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f87629291b35b31fb9f91f4a61c7e28",
     "grade": true,
     "grade_id": "cell-68578dd758ce6174",
     "locked": true,
     "points": 0.01,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do not change this cell\n",
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(150, factor=.1, noise=.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
=======
   "id": "81fed4e7",
   "metadata": {},
>>>>>>> 0af341e (22f basic (#89))
   "source": [
    "### Test 1: SVM accuracy (0.69 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa1a0950",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e3c1fad99095246f9aab0334f14512a",
     "grade": true,
     "grade_id": "cell-1759990cd7cea5ce",
     "locked": true,
     "points": 0.69,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test = X[100:], y[100:]\n",
    "X, y = X[:100], y[:100]\n",
    "y[y==0] = -1 # for convenience with formulas\n",
    "y_test[y_test==0] = -1\n",
    "clf = SVM(epochs=150, lr=0.1, batch_size=20, verbose=False, kernel_function=rbf)\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(X_test)\n",
    "assert accuracy_score(y_test, pred) > 0.95"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
=======
   "id": "2b31df66",
   "metadata": {},
>>>>>>> 0af341e (22f basic (#89))
   "source": [
    "### Test 2: Kernel (0.3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4220b86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a296d1662f5027b9b8727cd724f19ab5",
     "grade": true,
     "grade_id": "cell-a92ec82e4098bdd2",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9fdff277d48f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0000e+00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.2897e-11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.2897e-11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0000e+00\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "assert (np.allclose(rbf(X_kernel, X_kernel).detach().cpu().numpy(), np.array([[1.0000e+00, 2.2897e-11],[2.2897e-11, 1.0000e+00]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fe23193132d13f7e35367233cf5bfa9f24bfdfb7008196a20ea5d3c00f0fd44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}